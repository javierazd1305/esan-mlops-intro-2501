{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5a68ff-1a59-4291-b097-a05c9476be5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.functions import mean, min, max\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e526b628-92b4-48e3-b2a5-ce5c4c61fae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_atributos = spark.table(\"databricks_clase.prueba_schema.base_atributos\")\n",
    "base_cliente = spark.table(\"databricks_clase.prueba_schema.base_cliente\")\n",
    "base_trx = spark.table(\"databricks_clase.prueba_schema.base_trx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "196f4c16-831b-4ac3-af2b-960c8affc428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "join_1 = base_atributos.join(\n",
    "    base_cliente,\n",
    "    on=[\"periodo\", \"id_cliente\"],  \n",
    "    how=\"left\"  \n",
    ")\n",
    "\n",
    "tabla_consolidada = join_1.join(\n",
    "    base_trx,\n",
    "    on=[\"periodo\", \"id_cliente\"],  \n",
    "    how=\"left\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9265c07-ad06-41fc-aab4-9619fa1510e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reemplazar valores nulos en columnas categóricas\n",
    "tabla_consolidada = tabla_consolidada.fillna({\n",
    "    \"tipo_producto\": \"Desconocido\",\n",
    "    \"departamento\": \"Desconocido\",\n",
    "    \"canal\": \"Desconocido\"\n",
    "})\n",
    "\n",
    "# Reemplazar valores nulos en columnas numéricas con la mediana\n",
    "numeric_cols = [\"monto_1m\", \"monto_2m\", \"monto_3m\", \"frecuencia_1m\", \"frecuencia_2m\", \"frecuencia_3m\"]\n",
    "for col_name in numeric_cols:\n",
    "    median_value = tabla_consolidada.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    tabla_consolidada = tabla_consolidada.fillna({col_name: median_value})\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Crear nuevas características\n",
    "tabla_consolidada = tabla_consolidada.withColumn(\n",
    "    \"monto_total\",\n",
    "    expr(\"monto_1m + monto_2m + monto_3m + monto_4m + monto_5m + monto_6m\")\n",
    ")\n",
    "\n",
    "tabla_consolidada = tabla_consolidada.withColumn(\n",
    "    \"tendencia_monto\",\n",
    "    expr(\"(monto_1m - monto_6m) / monto_6m\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b2faa2c-7423-4f72-bbcb-45b11926f22a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabla_consolidada = tabla_consolidada.drop('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6864d1c-007b-43d9-9b7b-8cf61b7f9db4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabla_consolidada = tabla_consolidada.filter(col(\"flg_churn\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43779ce2-7bfb-4021-bf35-bdd9d50221f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------\n periodo            | 0      \n id_cliente         | 0      \n tiempo_permanencia | 0      \n flg_vip            | 0      \n incidencias_a      | 357723 \n incidencias_b      | 307397 \n tipo_producto      | 0      \n periodo_creacion   | 388469 \n departamento       | 0      \n segmento_pago      | 388469 \n canal              | 0      \n segmento_cliente   | 388469 \n crossell           | 388469 \n tasa               | 504    \n monto_1m           | 0      \n monto_2m           | 0      \n monto_3m           | 0      \n monto_4m           | 0      \n monto_5m           | 0      \n monto_6m           | 0      \n cantidad_1m        | 0      \n cantidad_2m        | 0      \n cantidad_3m        | 0      \n cantidad_6m        | 0      \n frecuencia_1m      | 0      \n frecuencia_2m      | 0      \n frecuencia_3m      | 0      \n ultima_compra_1m   | 0      \n ultima_compra_2m   | 55791  \n ultima_compra_3m   | 80756  \n flg_churn          | 0      \n monto_total        | 0      \n tendencia_monto    | 0      \n\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista de columnas\n",
    "columnas = tabla_consolidada.columns\n",
    "\n",
    "# Contar valores nulos en cada columna\n",
    "nulos = tabla_consolidada.agg(\n",
    "    *[sum(col(c).isNull().cast(\"int\")).alias(c) for c in columnas]\n",
    ")\n",
    "\n",
    "# Mostrar el resultado\n",
    "nulos.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e0806a6-2fdf-4764-ae89-e426d590c9f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reemplazar con 0\n",
    "columnas_cero = [\"incidencias_a\", \"incidencias_b\", \"crossell\", \"ultima_compra_2m\", \"ultima_compra_3m\"]\n",
    "tabla_consolidada = tabla_consolidada.fillna({col: 0 for col in columnas_cero})\n",
    "\n",
    "# Reemplazar con valor predeterminado\n",
    "periodo_minimo = tabla_consolidada.select(min(\"periodo\")).collect()[0][0]\n",
    "tabla_consolidada = tabla_consolidada.fillna({\"periodo_creacion\": periodo_minimo})\n",
    "\n",
    "# Reemplazar con -1\n",
    "columnas_menos_uno = [\"segmento_pago\", \"segmento_cliente\"]\n",
    "tabla_consolidada = tabla_consolidada.fillna({col: -1 for col in columnas_menos_uno})\n",
    "\n",
    "# Imputar con la media\n",
    "tasa_media = tabla_consolidada.select(mean(\"tasa\")).collect()[0][0]\n",
    "tabla_consolidada = tabla_consolidada.fillna({\"tasa\": tasa_media})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40c9132e-9639-4ec8-9b76-cdce87f8bb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------\n periodo            | 0   \n id_cliente         | 0   \n tiempo_permanencia | 0   \n flg_vip            | 0   \n incidencias_a      | 0   \n incidencias_b      | 0   \n tipo_producto      | 0   \n periodo_creacion   | 0   \n departamento       | 0   \n segmento_pago      | 0   \n canal              | 0   \n segmento_cliente   | 0   \n crossell           | 0   \n tasa               | 0   \n monto_1m           | 0   \n monto_2m           | 0   \n monto_3m           | 0   \n monto_4m           | 0   \n monto_5m           | 0   \n monto_6m           | 0   \n cantidad_1m        | 0   \n cantidad_2m        | 0   \n cantidad_3m        | 0   \n cantidad_6m        | 0   \n frecuencia_1m      | 0   \n frecuencia_2m      | 0   \n frecuencia_3m      | 0   \n ultima_compra_1m   | 0   \n ultima_compra_2m   | 0   \n ultima_compra_3m   | 0   \n flg_churn          | 0   \n monto_total        | 0   \n tendencia_monto    | 0   \n\n"
     ]
    }
   ],
   "source": [
    "nulos_final = tabla_consolidada.agg(\n",
    "    *[sum(col(c).isNull().cast(\"int\")).alias(c) for c in columnas]\n",
    ")\n",
    "\n",
    "nulos_final.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e2f331-94d4-4d62-8335-8ec1d1c3b406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `databricks_clase`.`prueba_schema`.`base_consolidada` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n",
       "'DeleteFromTable true\n",
       "+- 'UnresolvedRelation [databricks_clase, prueba_schema, base_consolidada], [__required_write_privileges__=DELETE], false\n",
       "\n",
       "\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:322)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:286)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:287)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:286)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:286)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:286)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:286)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:261)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:406)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:246)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:233)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:233)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:406)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:171)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:211)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:171)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:68)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:63)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:473)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:443)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:473)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:276)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:512)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:593)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:145)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:593)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1224)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:592)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:588)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:588)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:270)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1676)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1737)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:297)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:251)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1367)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1367)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:123)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1040)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1003)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1064)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:340)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:440)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:464)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:459)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:1237)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1228)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1219)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:120)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:120)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1151)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1613)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:816)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1040)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1029)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1075)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1075)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:777)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:870)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:641)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:636)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:559)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:342)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:322)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:286)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:287)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:286)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:286)\n",
       "\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:286)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:286)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:261)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:406)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:246)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:233)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:233)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:406)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:171)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:211)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:171)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:68)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:63)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:473)\n",
       "\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:443)\n",
       "\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:473)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:276)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:512)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:593)\n",
       "\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:145)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:593)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1224)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:592)\n",
       "\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:588)\n",
       "\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:588)\n",
       "\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:270)\n",
       "\t\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1676)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
       "\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
       "\t\t... 71 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `databricks_clase`.`prueba_schema`.`base_consolidada` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "TABLE_OR_VIEW_NOT_FOUND",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42P01",
        "stackTrace": null,
        "startIndex": 12,
        "stopIndex": 58
       },
       "stackFrames": [
        "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `databricks_clase`.`prueba_schema`.`base_consolidada` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n'DeleteFromTable true\n+- 'UnresolvedRelation [databricks_clase, prueba_schema, base_consolidada], [__required_write_privileges__=DELETE], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:322)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:286)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:286)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:261)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:406)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:246)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:233)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:233)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:406)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:171)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:211)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:171)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:68)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:63)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:473)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:443)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:473)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:276)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:512)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:145)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1224)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:592)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:588)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:588)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:270)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1676)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1737)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:297)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:251)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1367)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1367)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:123)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1040)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1003)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1064)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:340)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:440)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:464)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:459)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:1237)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1228)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1219)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:120)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:120)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1151)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1613)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:816)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1040)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1029)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1075)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1075)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:777)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:870)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:641)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:295)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:291)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:636)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:559)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:342)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:322)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:286)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:287)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:286)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:286)\n\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:286)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:286)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:261)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:406)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:246)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:233)\n\t\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:233)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:406)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:171)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:211)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:171)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:68)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:94)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:63)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:473)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:443)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:473)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:276)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:512)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:593)\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:145)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:593)\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1224)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:592)\n\t\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:588)\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1360)\n\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:588)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:270)\n\t\tat scala.util.Try$.apply(Try.scala:213)\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1676)\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n\t\t... 71 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DELETE FROM databricks_clase.prueba_schema.base_consolidada;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8cad776-3ed9-4382-a36b-9b41fc7ae7e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS databricks_clase.prueba_schema.base_consolidada PURGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2556b577-99c2-47ce-9b90-76db35441a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- periodo: long (nullable = true)\n |-- id_cliente: long (nullable = true)\n |-- tiempo_permanencia: long (nullable = true)\n |-- flg_vip: double (nullable = true)\n |-- incidencias_a: double (nullable = false)\n |-- incidencias_b: double (nullable = false)\n |-- tipo_producto: string (nullable = false)\n |-- periodo_creacion: long (nullable = false)\n |-- departamento: string (nullable = false)\n |-- segmento_pago: long (nullable = false)\n |-- canal: string (nullable = false)\n |-- segmento_cliente: long (nullable = false)\n |-- crossell: double (nullable = false)\n |-- tasa: double (nullable = false)\n |-- monto_1m: double (nullable = false)\n |-- monto_2m: double (nullable = false)\n |-- monto_3m: double (nullable = false)\n |-- monto_4m: double (nullable = true)\n |-- monto_5m: double (nullable = true)\n |-- monto_6m: double (nullable = true)\n |-- cantidad_1m: double (nullable = true)\n |-- cantidad_2m: double (nullable = true)\n |-- cantidad_3m: double (nullable = true)\n |-- cantidad_6m: double (nullable = true)\n |-- frecuencia_1m: double (nullable = false)\n |-- frecuencia_2m: double (nullable = false)\n |-- frecuencia_3m: double (nullable = false)\n |-- ultima_compra_1m: double (nullable = true)\n |-- ultima_compra_2m: double (nullable = false)\n |-- ultima_compra_3m: double (nullable = false)\n |-- flg_churn: double (nullable = true)\n |-- monto_total: double (nullable = true)\n |-- tendencia_monto: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "tabla_consolidada.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba4d06a5-e13f-4242-8ba7-aca586880e92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE databricks_clase.prueba_schema.base_consolidada (\n",
    "    periodo BIGINT,\n",
    "    id_cliente BIGINT,\n",
    "    tiempo_permanencia BIGINT,\n",
    "    flg_vip DOUBLE,\n",
    "    incidencias_a DOUBLE NOT NULL,\n",
    "    incidencias_b DOUBLE NOT NULL,\n",
    "    tipo_producto STRING NOT NULL,\n",
    "    periodo_creacion BIGINT NOT NULL,\n",
    "    departamento STRING NOT NULL,\n",
    "    segmento_pago BIGINT NOT NULL,\n",
    "    canal STRING NOT NULL,\n",
    "    segmento_cliente BIGINT NOT NULL,\n",
    "    crossell DOUBLE NOT NULL,\n",
    "    tasa DOUBLE NOT NULL,\n",
    "    monto_1m DOUBLE NOT NULL,\n",
    "    monto_2m DOUBLE NOT NULL,\n",
    "    monto_3m DOUBLE NOT NULL,\n",
    "    monto_4m DOUBLE,\n",
    "    monto_5m DOUBLE,\n",
    "    monto_6m DOUBLE,\n",
    "    cantidad_1m DOUBLE,\n",
    "    cantidad_2m DOUBLE,\n",
    "    cantidad_3m DOUBLE,\n",
    "    cantidad_6m DOUBLE,\n",
    "    frecuencia_1m DOUBLE NOT NULL,\n",
    "    frecuencia_2m DOUBLE NOT NULL,\n",
    "    frecuencia_3m DOUBLE NOT NULL,\n",
    "    ultima_compra_1m DOUBLE,\n",
    "    ultima_compra_2m DOUBLE NOT NULL,\n",
    "    ultima_compra_3m DOUBLE NOT NULL,\n",
    "    flg_churn DOUBLE,\n",
    "    monto_total DOUBLE,\n",
    "    tendencia_monto DOUBLE\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5466d41c-93c6-4801-9348-94dbba28e53e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>tiempo_permanencia</th>\n",
       "      <th>flg_vip</th>\n",
       "      <th>incidencias_a</th>\n",
       "      <th>incidencias_b</th>\n",
       "      <th>tipo_producto</th>\n",
       "      <th>periodo_creacion</th>\n",
       "      <th>departamento</th>\n",
       "      <th>segmento_pago</th>\n",
       "      <th>canal</th>\n",
       "      <th>segmento_cliente</th>\n",
       "      <th>crossell</th>\n",
       "      <th>tasa</th>\n",
       "      <th>monto_1m</th>\n",
       "      <th>monto_2m</th>\n",
       "      <th>monto_3m</th>\n",
       "      <th>monto_4m</th>\n",
       "      <th>monto_5m</th>\n",
       "      <th>monto_6m</th>\n",
       "      <th>cantidad_1m</th>\n",
       "      <th>cantidad_2m</th>\n",
       "      <th>cantidad_3m</th>\n",
       "      <th>cantidad_6m</th>\n",
       "      <th>frecuencia_1m</th>\n",
       "      <th>frecuencia_2m</th>\n",
       "      <th>frecuencia_3m</th>\n",
       "      <th>ultima_compra_1m</th>\n",
       "      <th>ultima_compra_2m</th>\n",
       "      <th>ultima_compra_3m</th>\n",
       "      <th>flg_churn</th>\n",
       "      <th>monto_total</th>\n",
       "      <th>tendencia_monto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202401</td>\n",
       "      <td>131</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>202401</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>6.708084</td>\n",
       "      <td>-16.118096</td>\n",
       "      <td>6.579251</td>\n",
       "      <td>-16.118096</td>\n",
       "      <td>5.991465</td>\n",
       "      <td>-16.118096</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>-16.118096</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-16.118096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-29.075487</td>\n",
       "      <td>-1.416183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202401</td>\n",
       "      <td>164</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>202401</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>10.190057</td>\n",
       "      <td>9.484025</td>\n",
       "      <td>9.330521</td>\n",
       "      <td>9.675740</td>\n",
       "      <td>9.978711</td>\n",
       "      <td>9.188810</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.847863</td>\n",
       "      <td>0.108964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  id_cliente  ...  monto_total  tendencia_monto\n",
       "0   202401         131  ...   -29.075487        -1.416183\n",
       "1   202401         164  ...    57.847863         0.108964\n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_consolidada.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e0d7722-d008-4743-b3ca-eecff5765703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Guardar la tabla en Unity Catalog\n",
    "tabla_consolidada.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"databricks_clase.prueba_schema.base_consolidada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f7b477-c984-410e-82d9-0e26de658cb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_consolidado_lec = spark.read.table(\"databricks_clase.prueba_schema.base_consolidada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c00584-5ff6-486b-ac2e-560c1b7fdfdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+-------+-------------+-------------+-------------+----------------+------------+-------------+-----------+----------------+--------+------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------+-------------+-------------+----------------+----------------+----------------+---------+-------------------+--------------------+\n|periodo|id_cliente|tiempo_permanencia|flg_vip|incidencias_a|incidencias_b|tipo_producto|periodo_creacion|departamento|segmento_pago|      canal|segmento_cliente|crossell|  tasa|          monto_1m|          monto_2m|          monto_3m|            monto_4m|          monto_5m|          monto_6m|         cantidad_1m|         cantidad_2m|         cantidad_3m|         cantidad_6m|frecuencia_1m|frecuencia_2m|frecuencia_3m|ultima_compra_1m|ultima_compra_2m|ultima_compra_3m|flg_churn|        monto_total|     tendencia_monto|\n+-------+----------+------------------+-------+-------------+-------------+-------------+----------------+------------+-------------+-----------+----------------+--------+------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------+-------------+-------------+----------------+----------------+----------------+---------+-------------------+--------------------+\n| 202401|       131|                39|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 6.708084083975169|-16.11809565095832|  6.57925121214899|  -16.11809565095832| 5.991464547357982|-16.11809565095832|  1.3862943861198904|  -16.11809565095832|   0.693147230559944|  -16.11809565095832|          4.0|          0.0|          2.0|            29.0|             0.0|            24.0|      0.0| -29.07548710939282|  -1.416183414544778|\n| 202401|       164|                16|    0.0|          0.0|          3.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 10.19005650570419| 9.484024934791716| 9.330520532241156|   9.675739667533662| 9.978710973778353| 9.188810253436037|  3.0910424579037703|  2.4849066581213335|  2.5649493651538444|  2.4849066581213335|         16.0|         10.0|         12.0|            31.0|            30.0|            30.0|      0.0|  57.84786286748512| 0.10896364432966173|\n| 202401|       247|                 3|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 10.03878301328151| 9.459541457617476| 9.659184203392677|   7.977625098818898|-16.11809565095832|-16.11809565095832|   4.356708827971643|   3.988984048416126|   4.143134727978834|  -16.11809565095832|         25.0|         20.0|         20.0|            31.0|            30.0|            29.0|      0.0|  4.898942471193919| -1.6228268668131798|\n| 202401|       366|                 0|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 6.824373670151782|-16.11809565095832|-16.11809565095832|  -16.11809565095832|-16.11809565095832|-16.11809565095832|   0.693147230559944|  -16.11809565095832|  -16.11809565095832|  -16.11809565095832|          2.0|          0.0|          0.0|            20.0|             0.0|             0.0|      1.0| -73.76610458463982| -1.4233982610561087|\n| 202401|       473|                21|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0| 0.028| 2.351375266687287|3.0445224424853277| 4.867534451224813|   6.292124541035102|-16.11809565095832| 2.351375266687287|9.999999505838704E-8|9.999999505838704E-8|  1.6094379324341002|9.999999505838704E-8|          1.0|          1.0|          4.0|            13.0|            16.0|            26.0|      1.0| 2.7888363171614956|                 0.0|\n| 202401|       559|                10|    1.0|          0.0|         16.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344|10.059935591416346|10.045704392231425|  9.44041981429945|  10.651383301146643| 9.893094733804686|10.242905446449472|   4.820281566411489|  5.1298987155147895|   4.394449155907006|   5.081404365605581|         20.0|         17.0|         14.0|            29.0|            31.0|            26.0|      0.0|  60.33344327934802|-0.01786308152405...|\n| 202401|       629|                34|    0.0|          1.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 4.548599835557898|-16.11809565095832|-16.11809565095832|   5.752572639143094|5.7853624619558435|-16.11809565095832|9.999999505838704E-8|  -16.11809565095832|  -16.11809565095832|  -16.11809565095832|          1.0|          0.0|          0.0|            10.0|             0.0|             0.0|      0.0|-32.267752016218125|  -1.282204544138405|\n| 202401|       647|                13|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 8.063377822398513| 7.636752112484019| 7.901747518557154|   8.106363720839084|7.4650827364568215|7.3746290152816405|  3.5263605275573378|  3.0910424579037703|  3.2958368697080327|    2.89037176345172|         21.0|         13.0|         17.0|            31.0|            30.0|            28.0|      0.0|  46.54795292601723|  0.0933943667796242|\n| 202401|       723|                15|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 8.207674424382537| 7.090076835859425| 5.722800480819017|  6.6608311991305325| 7.147873934580962| 5.327876169275018|   0.693147230559944|9.999999505838704E-8|9.999999505838704E-8|   0.693147230559944|          2.0|          1.0|          1.0|            31.0|            13.0|            15.0|      0.0|  40.15713304404749|  0.5405152378943866|\n| 202401|       746|                33|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344|6.8517138882042765| 6.829793737620533| 7.057036981784024|   6.626717749381475| 5.975081068111588| 6.512487995998897|  3.2958368697080327|  3.3322045137466327|  3.1780538345146123|  2.9444389844295986|          9.0|         14.0|         14.0|            27.0|            31.0|            30.0|      0.0|  39.85283142110079|0.052088524756405116|\n| 202401|       769|                39|    0.0|          0.0|          7.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 9.270588452330955| 8.873748128168396| 8.660600654728295|   9.023890304610498| 8.669948612625593| 8.928839158612734|   4.787491743615379|   4.406719248483765|   4.356708827971643|   4.521788578135997|         24.0|         19.0|         22.0|            30.0|            31.0|            28.0|      0.0| 53.427615311076465|0.038274773198100555|\n| 202401|       905|                37|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344|  7.50108212431512| 7.904703913910647| 5.220355825618865|  -16.11809565095832|-16.11809565095832|-16.11809565095832|   2.833213349938569|   2.639057336758116|   0.693147230559944|  -16.11809565095832|         12.0|          9.0|          2.0|            31.0|            29.0|            30.0|      1.0| -27.72814508903033| -1.4653826535561685|\n| 202401|      1214|                39|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344|  6.60577142195475| 6.490571778071542| 5.948296051967632|  6.4121466211851565| 7.128495945760229|  5.86929691341626|   2.772588728489781|  2.3978952818892796|   2.079441554179836|  2.1972245884473303|         10.0|          8.0|          6.0|            30.0|            28.0|            29.0|      0.0|  38.45457873235557| 0.12547917057237787|\n| 202401|      1313|                18|    0.0|          1.0|          1.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 5.190008063598381| 0.693147230559944| 5.704781975322285|9.999999505838704E-8|-16.11809565095832|  4.58496747969098|  1.6094379324341002|9.999999505838704E-8|   0.693147230559944|9.999999505838704E-8|          2.0|          1.0|          2.0|            25.0|             9.0|            24.0|      0.0|0.05480919821326591| 0.13196180487373493|\n| 202401|      1533|                13|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344|   6.2633982627821| 6.405228458196131| 6.359573868845388|  -16.11809565095832| 6.445719819544308| 6.733401891956407|9.999999505838704E-8|  1.0986123220014423|   0.693147230559944|9.999999505838704E-8|          1.0|          3.0|          2.0|             2.0|            28.0|             8.0|      0.0| 16.089226650366015|-0.06980180846412344|\n| 202401|      1561|                39|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 5.153291595075814| 7.369663730576521| 6.666193142271233|   4.776599302458083|7.0880748331889185| 6.436310612100228|9.999999505838704E-8|  2.3025851029940454|  1.9459101633410276|  1.7917594858947217|          1.0|         10.0|          5.0|             8.0|            30.0|            30.0|      0.0| 37.490133215670795|-0.19934075503011706|\n| 202401|      1707|                 8|    0.0|          0.0|          2.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 8.591168297619385|  9.34400200612766| 8.375790904434183|    4.87519732396451| 4.800736970354435|  7.48481236510794|   4.644390900102911|   5.123963979998497|   4.317488114869644|   3.828641398663008|         27.0|         29.0|         18.0|            31.0|            31.0|            30.0|      0.0|  43.47170786760811| 0.14781344922806086|\n| 202401|      1912|                 0|    0.0|          2.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 7.863266724048035|-16.11809565095832|-16.11809565095832|  -16.11809565095832|-16.11809565095832|-16.11809565095832|  1.3862943861198904|  -16.11809565095832|  -16.11809565095832|  -16.11809565095832|          4.0|          0.0|          0.0|             8.0|             0.0|             0.0|      1.0| -72.72721153074357| -1.4878533354267889|\n| 202401|      1998|                 6|    0.0|          0.0|          5.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 9.925845735151684| 9.994556934678654| 9.240578555046495|   9.729350213485803| 9.633245842310476| 3.218875828868201|    5.25227342857019|  5.1298987155147895|   4.499809671441376|9.999999505838704E-8|         31.0|         29.0|         25.0|            31.0|            31.0|            30.0|      0.0|  51.74245310954131|  2.0836373513176936|\n| 202401|      2056|                21|    0.0|          0.0|          0.0|  Desconocido|          202401| Desconocido|           -1|Desconocido|              -1|     0.0|0.0344| 3.806662491992542|-16.11809565095832| 4.615120517831358|   5.272999559076568| 5.105945474506641|-16.11809565095832|9.999999505838704E-8|  -16.11809565095832|   0.693147230559944|  -16.11809565095832|          1.0|          0.0|          2.0|             1.0|             0.0|            12.0|      0.0|-13.435463258509532| -1.2361732163914918|\n+-------+----------+------------------+-------+-------------+-------------+-------------+----------------+------------+-------------+-----------+----------------+--------+------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+-------------+-------------+-------------+----------------+----------------+----------------+---------+-------------------+--------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_consolidado_lec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e377af31-bb0b-4894-8ed7-44b7da1bb666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "periodo_max =df_consolidado_lec.agg(max(\"periodo\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61069490-e293-4a56-8ec3-4e37a9ff2800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabla_consolidada_mensual = df_consolidado_lec.filter(df_consolidado_lec.periodo == periodo_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44efe921-08c6-40da-87f8-4bd2a026bffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS databricks_clase.prueba_schema.base_consolidada_mensual PURGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2563207a-58e4-46f9-8c1e-4000bdeacda4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE databricks_clase.prueba_schema.base_consolidada_mensual (\n",
    "    periodo BIGINT,\n",
    "    id_cliente BIGINT,\n",
    "    tiempo_permanencia BIGINT,\n",
    "    flg_vip DOUBLE,\n",
    "    incidencias_a DOUBLE NOT NULL,\n",
    "    incidencias_b DOUBLE NOT NULL,\n",
    "    tipo_producto STRING NOT NULL,\n",
    "    periodo_creacion BIGINT NOT NULL,\n",
    "    departamento STRING NOT NULL,\n",
    "    segmento_pago BIGINT NOT NULL,\n",
    "    canal STRING NOT NULL,\n",
    "    segmento_cliente BIGINT NOT NULL,\n",
    "    crossell DOUBLE NOT NULL,\n",
    "    tasa DOUBLE NOT NULL,\n",
    "    monto_1m DOUBLE NOT NULL,\n",
    "    monto_2m DOUBLE NOT NULL,\n",
    "    monto_3m DOUBLE NOT NULL,\n",
    "    monto_4m DOUBLE,\n",
    "    monto_5m DOUBLE,\n",
    "    monto_6m DOUBLE,\n",
    "    cantidad_1m DOUBLE,\n",
    "    cantidad_2m DOUBLE,\n",
    "    cantidad_3m DOUBLE,\n",
    "    cantidad_6m DOUBLE,\n",
    "    frecuencia_1m DOUBLE NOT NULL,\n",
    "    frecuencia_2m DOUBLE NOT NULL,\n",
    "    frecuencia_3m DOUBLE NOT NULL,\n",
    "    ultima_compra_1m DOUBLE,\n",
    "    ultima_compra_2m DOUBLE NOT NULL,\n",
    "    ultima_compra_3m DOUBLE NOT NULL,\n",
    "    flg_churn DOUBLE,\n",
    "    monto_total DOUBLE,\n",
    "    tendencia_monto DOUBLE\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdf27286-b89d-4b88-93a4-5c3c2e1a84d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabla_consolidada_mensual.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"databricks_clase.prueba_schema.base_consolidada_mensual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0fbc5e3-e3fc-4d3d-b62f-586b343ddaca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7461771108931064,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04 ModelOps - Model Registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}